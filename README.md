# learn-eng
# ğŸŒŸ English Conversation Coach

**Offline English-speaking practice app powered by whisper.cpp (STT) and Piper (TTS).**
Practice real dialogues, speak naturally, and get pronunciation feedback â€” all processed on your device.

> ğŸ’¡ Works **100% offline** once installed.
> No API keys. No internet. No cloud. Everything runs locally.

---

# ğŸš€ Quick Start (Recommended)

This project includes a **fully automated installer**.
After cloning, just run:

```bash
git clone https://github.com/rahulhumie/learn-eng
cd learn-eng
./setup.sh
```

The installer will automatically:

* âœ“ Download & build **whisper.cpp**
* âœ“ Download the **Whisper base.en model**
* âœ“ Download **Piper TTS**
* âœ“ Download the **Amy voice model**
* âœ“ Install **Node.js dependencies**
* âœ“ Install **ffmpeg** (if missing)
* âœ“ Create the `.env` file with correct paths
* âœ“ Make everything ready in **one step**

â± Takes **5â€“10 minutes** depending on your internet speed.

After setup:

```bash
npm start
```

Then open:

```
http://localhost:8000
```

---

# ğŸ¯ What This App Does

* Speak through real conversation scenarios
* App speaks its part (Piper TTS)
* You speak your part (whisper.cpp STT)
* Your response is checked with simple NLP scoring
* Get instant feedback and retry
* Fully offline â€” no data leaves your device

Great for beginners, kids, or conversational practice.

---

# ğŸ“¦ Prerequisites

You only need:

* **macOS or Linux**
  *(Windows users can use WSL2)*
* **Node.js 18+**
* **Python 3 + pip**
* **Homebrew (macOS)** or **apt (Linux)**
* Basic build tools (make, cmake)

> If something is missing, the setup script will tell you.

---

# ğŸ›  Manual Setup (If You Donâ€™t Want the Script)

### 1. Install dependencies

```bash
npm install
pip3 install piper-tts
```

### 2. Install whisper.cpp

```bash
git clone https://github.com/ggerganov/whisper.cpp
cd whisper.cpp
make
```

Download Whisper model:

```bash
bash ./models/download-ggml-model.sh base.en
```

### 3. Download Piper voice model

```bash
mkdir -p models
curl -L "https://huggingface.co/rhasspy/piper-voices/resolve/main/en/en_US/amy/medium/en_US-amy-medium.onnx" \
 -o models/en_US-amy-medium.onnx

curl -L "https://huggingface.co/rhasspy/piper-voices/resolve/main/en/en_US/amy/medium/en_US-amy-medium.onnx.json" \
 -o models/en_US-amy-medium.onnx.json
```

### 4. Install ffmpeg

```bash
brew install ffmpeg           # macOS
sudo apt install ffmpeg       # Linux
```

### 5. Create `.env`

```bash
cp .env.example .env
```

Update model paths.

---

# â–¶ï¸ Running the App

```bash
npm start
```

Then visit:

```
http://localhost:8000
```

You can:

* Choose a scenario
* Listen to AI lines
* Speak your lines
* Retry mismatched sentences
* View conversation log

---

# ğŸ§  How It Works

### ğŸŸ¦ Speech-to-Text (STT): whisper.cpp

Browser records audio â†’ sent to server â†’ converted with ffmpeg â†’ transcribed locally.

### ğŸŸ© Text-to-Speech (TTS): Piper

Server runs Piper with your model â†’ returns WAV â†’ browser plays it.

### ğŸŸ§ NLP Matching

Your reply is scored using:

* Token overlap (Jaccard)
* Levenshtein similarity
* â‰¥ 80% = accepted

---


# â— Troubleshooting

### âŒ No Audio?

* Increase volume
* Browser sometimes needs one click before playing sound

### âŒ Mic not working?

* Allow mic in browser
* Reload the page

### âŒ Setup script fails?

* Run it with debug:

```bash
bash -x setup.sh
```

---



